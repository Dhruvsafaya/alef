package com.alefeducation.dimensions.course.transform

import com.alefeducation.base.SparkBatchService
import com.alefeducation.bigdata.Sink
import com.alefeducation.dimensions.course.transform.CourseDeletedTransform.addDefaultColumn
import com.alefeducation.dimensions.course.transform.CourseMutatedTransform._
import com.alefeducation.schema.internal.ControlTableUtils.ProductMaxIdType
import com.alefeducation.service.DataSink
import com.alefeducation.util.BatchTransformerUtility._
import com.alefeducation.util.Constants.{CourseActiveStatusVal, CourseInactiveStatusVal}
import com.alefeducation.util.{Helpers, SparkSessionUtils}
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.functions.{col, date_format, lit}
import org.apache.spark.sql.{DataFrame, Row, SparkSession}

class CourseMutatedTransform(val session: SparkSession, val service: SparkBatchService) {

  def getLatestRecords(df: DataFrame, idCol: String, timeCol: String): DataFrame = {
    val rdd: RDD[(Row, Row)] = df.rdd.map(row => (Row(row.getAs[Any](idCol)), row))

    val latestRecordsRDD: RDD[Row] = rdd
      .reduceByKey {
        case (row1, row2) =>
          val time1 = row1.getAs[String](timeCol)
          val time2 = row2.getAs[String](timeCol)
          if (time1 > time2) row1 else row2
      }
      .map(_._2)

    val schema = df.schema
    df.sparkSession.createDataFrame(latestRecordsRDD, schema)
  }

  private def getExistingCourses(
      courseDelta: Option[DataFrame],
      coursePublished: Option[DataFrame]
  ): Option[DataFrame] = {
    val courseDeltaFiltered = courseDelta.map(
      _.filter(col("course_status") === lit(CourseActiveStatusVal))
        .selectColumnsWithMapping(ExistingCourseCols)
        .withColumn("occurredOn", date_format(col("occurredOn"), Helpers.DateTimeFormat))
    )
    val coursePublishedMapped = coursePublished.map(_.select(ExistingCourseCols.values.toSeq.map(col): _*))
    val existingCourses: Option[DataFrame] = courseDeltaFiltered.unionOptionalByName(coursePublishedMapped)

    existingCourses.map(_.transform(getLatestRecords(_, idCol = "id", timeCol = "occurredOn")).drop("occurredOn"))
  }

  def transform(): List[Option[Sink]] = {
    val coursePublished: Option[DataFrame] = service.readUniqueOptional(
      CoursePublishedParquetSource,
      session,
      uniqueColNames = List("id", "courseVersion")
    )
    val deltaCourses: Option[DataFrame] = service.readOptional(CourseDeltaSource, session)

    val existingCourses: Option[DataFrame] = getExistingCourses(deltaCourses, coursePublished)

    val courseUpdatedRaw: Option[DataFrame] = service.readUniqueOptional(
      CourseUpdatedParquetSource,
      session,
      extraProps = List(("mergeSchema", "true")),
      uniqueColNames = List("id", "courseVersion")
    )
    val courseUpdated = courseUpdatedRaw.map(
      _.transform(addDefaultColumn)
        .filter(col("courseStatus") === "PUBLISHED")
    )

    val coursesUpdatedEnriched: Option[DataFrame] = courseUpdated.map(
      _.joinOptional(existingCourses, Seq("id"), "left")
    )

    val mutated: Option[DataFrame] = coursePublished
      .map(_.selectColumnsWithMapping(CourseCols))
      .unionOptionalByName(coursesUpdatedEnriched.map(_.selectColumnsWithMapping(CourseCols)))

    val startId = service.getStartIdUpdateStatus(CourseKey)
    val mutatedIWH = mutated.flatMap(
      _.transformForIWH2(
        CourseIWHCols,
        CourseEntityPrefix,
        0, //unnecessary field
        attachedEvents = Nil,
        detachedEvents = Nil,
        List("course_id"),
        inactiveStatus = CourseInactiveStatusVal
      )
        //drop column generated by transformForIWH2
        .drop("course_iwh_type")
        .genDwId("rel_course_dw_id", startId)
        .checkEmptyDf
    )

    List(
      mutatedIWH.map(DataSink(CourseMutatedTransformedSink, _, controlTableUpdateOptions = Map(ProductMaxIdType -> CourseKey)))
    )
  }
}

object CourseMutatedTransform {
  val CourseKey = "dim_course"
  val CourseTransformService = "course-mutated-transform"
  val CourseEntityPrefix = "course"
  val CourseMutatedTransformedSink = "parquet-course-mutated-transformed-source"

  val CoursePublishedParquetSource = "parquet-course-published-source"
  val CourseUpdatedParquetSource = "parquet-course-details-updated-source"
  val CourseDeltaSource = "delta-course-sink"

  private val ExistingCourseCols: Map[String, String] = Map(
    "course_id" -> "id",
    "course_organization" -> "organisation",
    "course_description" -> "description",
    "course_goal" -> "goal",
    "course_created_time" -> "occurredOn",
  )

  private val CourseCols: Map[String, String] = Map(
    "id" -> "course_id",
    "name" -> "course_name",
    "courseType" -> "courseType",
    "code" -> "course_code",
    "organisation" -> "course_organization",
    "description" -> "course_description",
    "goal" -> "course_goal",
    "langCode" -> "course_lang_code",
    "occurredOn" -> "occurredOn",
    "eventType" -> "eventType",
    "configuration.programEnabled" -> "course_program_enabled",
    "configuration.resourcesEnabled" -> "course_resources_enabled",
    "configuration.placementType" -> "course_placement_type"
  )

  private val CourseIWHCols: Map[String, String] = Map(
    "course_id" -> "course_id",
    "course_name" -> "course_name",
    "course_type" -> "course_iwh_type",
    "courseType" -> "course_type",
    "course_code" -> "course_code",
    "course_organization" -> "course_organization",
    "course_description" -> "course_description",
    "course_goal" -> "course_goal",
    "course_lang_code" -> "course_lang_code",
    "occurredOn" -> "occurredOn",
    "course_status" -> "course_status",
    "course_program_enabled" -> "course_program_enabled",
    "course_resources_enabled" -> "course_resources_enabled",
    "course_placement_type" -> "course_placement_type"
  )

  private val session: SparkSession = SparkSessionUtils.getSession(CourseTransformService)
  private val service = new SparkBatchService(CourseTransformService, session)

  def main(args: Array[String]): Unit = {
    val transformer = new CourseMutatedTransform(session, service)
    service.runAll(transformer.transform().flatten)
  }
}
